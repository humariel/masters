{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "outstanding-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import sqrtm\n",
    "import pickle\n",
    "from scipy.stats import truncnorm\n",
    "# modules\n",
    "from Ops.spectral_normalization import SpectralConv2D, SpectralDense\n",
    "from Ops.ops import ResnetBlock, ResnetBlockUp, ResnetBlockDown\n",
    "from Ops.attention import Attention\n",
    "from Ops.global_sum_pooling import GlobalSumPooling2D\n",
    "from Ops.conditional_batch_normalization import ConditionalBatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "atmospheric-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale an array of images to a new size\n",
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        # store\n",
    "        images_list.append(new_image)\n",
    "    return np.asarray(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "optional-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes images have any shape and pixels in [0,255]\n",
    "def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
    "    # load inception v3 model\n",
    "    model = InceptionV3()\n",
    "    # enumerate splits of images/predictions\n",
    "    scores = list()\n",
    "    n_part = math.floor(images.shape[0] / n_split)\n",
    "    for i in range(n_split):\n",
    "        # retrieve images\n",
    "        ix_start, ix_end = i * n_part, (i+1) * n_part\n",
    "        subset = images[ix_start:ix_end]\n",
    "        # convert from uint8 to float32\n",
    "        subset = subset.astype('float32')\n",
    "        # scale images to the required size\n",
    "        subset = scale_images(subset, (299,299,3))\n",
    "        # pre-process images, scale to [-1,1]\n",
    "        subset = preprocess_input(subset)\n",
    "        # predict p(y|x)\n",
    "        p_yx = model.predict(subset)\n",
    "        # calculate p(y)\n",
    "        p_y = np.expand_dims(p_yx.mean(axis=0), 0)\n",
    "        # calculate KL divergence using log probabilities\n",
    "        kl_d = p_yx * (np.log(p_yx + eps) - np.log(p_y + eps))\n",
    "        # sum over classes\n",
    "        sum_kl_d = kl_d.sum(axis=1)\n",
    "        # average over images\n",
    "        avg_kl_d = np.mean(sum_kl_d)\n",
    "        # undo the log\n",
    "        is_score = np.exp(avg_kl_d)\n",
    "        # store\n",
    "        scores.append(is_score)\n",
    "    # average across images\n",
    "    is_avg, is_std = np.mean(scores), np.std(scores)\n",
    "    return is_avg, is_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "satisfied-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate frechet inception distance\n",
    "def calculate_fid(images1, images2):\n",
    "    model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
    "    # convert integer to floating point values\n",
    "    images1 = images1.astype('float32')\n",
    "    images2 = images2.astype('float32')\n",
    "    # resize images\n",
    "    images1 = scale_images(images1, (299,299,3))\n",
    "    images2 = scale_images(images2, (299,299,3))\n",
    "    # pre-process images\n",
    "    images1 = preprocess_input(images1)\n",
    "    images2 = preprocess_input(images2)\n",
    "    # calculate activations\n",
    "    act1 = model.predict(images1)\n",
    "    act2 = model.predict(images2)\n",
    "    # calculate mean and covariance statistics\n",
    "    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alive-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(n_samples, latent_dim=100, n_classes=10, bigGAN=False):\n",
    "    if not bigGAN:\n",
    "        # generate points in the latent space\n",
    "        z_input = np.random.randn(n_samples * latent_dim)\n",
    "        # reshape into a batch of inputs for the network\n",
    "        z_input = z_input.reshape(n_samples, latent_dim)\n",
    "    else:\n",
    "        z_input = truncnorm.rvs(-2, 2, size=(n_samples, latent_dim), random_state=None).astype(np.float32)\n",
    "        z_input = z_input * 2.0 # 2.0 is truncation value\n",
    "    # generate labels\n",
    "    labels = np.random.randint(0, n_classes, n_samples)\n",
    "    return [z_input, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reported-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_is_for_gan(generator, n_split=10, eps=1E-16, custom_objects=None):\n",
    "    generator = tf.keras.models.load_model(generator, custom_objects=custom_objects)\n",
    "    #generate latent points for 50k images\n",
    "    [z_input, labels] = generate_latent_points(25000)\n",
    "    images = generator.predict([z_input, labels])\n",
    "    images = (images*127.5) + 127.5\n",
    "    print('generated ', images.shape)\n",
    "    #calculate IS score\n",
    "    is_avg, is_std = calculate_inception_score(images, n_split=n_split)\n",
    "    print('score', is_avg, is_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recreational-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fid_for_gan(generator, custom_objects=None):\n",
    "    generator = tf.keras.models.load_model(generator, custom_objects=custom_objects)\n",
    "    #generate latent points for 50k images\n",
    "    [z_input, labels] = generate_latent_points(10000)\n",
    "    fake_images = generator.predict([z_input, labels])\n",
    "    fake_images = (fake_images*127.5) + 127.5\n",
    "    print('generated ', fake_images.shape)\n",
    "    (real_images, _), (_, _) = cifar10.load_data()\n",
    "    np.random.shuffle(real_images)\n",
    "    real_images = real_images[:10000]\n",
    "    #calculate FID score\n",
    "    fid = calculate_fid(real_images, fake_images)\n",
    "    print('FID', fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "whole-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_is_for_bigGAN(generator, n_split=10, eps=1E-16, custom_objects=None):\n",
    "    generator = tf.keras.models.load_model(generator, custom_objects=custom_objects)\n",
    "    #generate latent points for 50k images\n",
    "    [z_input, labels] = generate_latent_points(25000, latent_dim=128, bigGAN=True)\n",
    "    images = generator.predict([z_input, labels])\n",
    "    images = (images*127.5) + 127.5\n",
    "    print('generated ', images.shape)\n",
    "    #calculate IS score\n",
    "    is_avg, is_std = calculate_inception_score(images)\n",
    "    print('score', is_avg, is_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unavailable-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fid_for_bigGAN(generator, custom_objects=None):\n",
    "    generator = tf.keras.models.load_model(generator, custom_objects=custom_objects)\n",
    "    #generate latent points for 50k images\n",
    "    [z_input, labels] = generate_latent_points(10000, latent_dim=128, bigGAN=True)\n",
    "    fake_images = generator.predict([z_input, labels])\n",
    "    fake_images = (fake_images*127.5) + 127.5\n",
    "    print('generated ', fake_images.shape)\n",
    "    (real_images, _), (_, _) = cifar10.load_data()\n",
    "    np.random.shuffle(real_images)\n",
    "    real_images = real_images[:10000]\n",
    "    #calculate FID score\n",
    "    fid = calculate_fid(real_images, fake_images)\n",
    "    print('FID', fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-separation",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-tucson",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_1 (Base model)\n",
    "<p>Batch Size : 64</p>\n",
    "<p>D steps per G step = 1</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "smaller-democracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (25000, 32, 32, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5e960b808aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#measure IS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./history/acgan/acgan-cifar10-1/training_checkpoints/generator-e250.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcalc_is_for_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-26be35edab6f>\u001b[0m in \u001b[0;36mcalc_is_for_gan\u001b[0;34m(generator, n_split, eps, custom_objects)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generated '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#calculate IS score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mis_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_inception_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-205acbd7d699>\u001b[0m in \u001b[0;36mcalculate_inception_score\u001b[0;34m(images, n_split, eps)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# predict p(y|x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mp_yx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# calculate p(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_yx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/experiments/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/miniconda3/envs/experiments/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/experiments/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/experiments/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniconda3/envs/experiments/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/experiments/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/experiments/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/experiments/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/experiments/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan/acgan-cifar10-1/training_checkpoints/generator-e250.h5'\n",
    "calc_is_for_gan(generator, n_split=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan/acgan-cifar10-1/training_checkpoints/generator-e250.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "legitimate-carpet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2250 - out_fake_loss: 0.3515 - out_aux_loss: 0.8735 - out_fake_accuracy: 0.8516 - out_aux_out_aux_sparse_categorical_accuracy: 0.7696\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan/acgan-cifar10-1/training_checkpoints/discriminator-e250.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, [np.ones((10000,1)),testY])\n",
    "print(testX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-vocabulary",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_2 (Base model->Smaller Batch Size)\n",
    "<p>Batch Size : 32</p>\n",
    "<p>D steps per G step = 1</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan/acgan-cifar10-2/training_checkpoints/generator-e250.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan/acgan-cifar10-2/training_checkpoints/generator-e250.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "extended-flush",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 0s 3ms/step - loss: -2.0618 - out_fake_loss: -3.0276 - out_aux_loss: 0.9658 - out_fake_accuracy: 0.1098 - out_aux_out_aux_sparse_categorical_accuracy: 0.7614\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan/acgan-cifar10-2/training_checkpoints/discriminator-e250.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-connection",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_3 (Base model -> Bigger Batch Size)\n",
    "<p>Batch Size : 128</p>\n",
    "<p>D steps per G step = 1</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan/acgan-cifar10-3/training_checkpoints/generator-e250.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan/acgan-cifar10-3/training_checkpoints/generator-e250.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan/acgan-cifar10-3/training_checkpoints/discriminator-e250.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-basic",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_4 (Base model -> 50% fmap increase in G)\n",
    "<p>Batch Size : 64</p>\n",
    "<p>D steps per G step = 1</p>\n",
    "<p>G: all num_filters increased by 50%</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan/acgan-cifar10-4/training_checkpoints/generator-e250.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan/acgan-cifar10-4/training_checkpoints/generator-e250.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "possible-oxide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 0s 3ms/step - loss: -3.1748 - out_fake_loss: -4.1654 - out_aux_loss: 0.9906 - out_fake_accuracy: 0.0993 - out_aux_out_aux_sparse_categorical_accuracy: 0.7574\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan/acgan-cifar10-4/training_checkpoints/discriminator-e250.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-curtis",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_11 (Base model)\n",
    "<p>Batch Size : 64</p>\n",
    "<p>D steps per G step = 1</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sudden-chester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (25000, 32, 32, 3)\n",
      "score 5.099715 0.015241975\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan/acgan-cifar10-11/training_checkpoints/generator-e250.h5'\n",
    "calc_is_for_gan(generator, n_split=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "other-parade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "FID 75.07642039844332\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan/acgan-cifar10-11/training_checkpoints/generator-e250.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suburban-basket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 0s 3ms/step - loss: -2.6778 - out_fake_loss: -3.6830 - out_aux_loss: 1.0052 - out_fake_accuracy: 0.1029 - out_aux_out_aux_sparse_categorical_accuracy: 0.7570\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan/acgan-cifar10-11/training_checkpoints/discriminator-e250.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-poker",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_12 (Base model->Smaller Batch Size)\n",
    "<p>Batch Size : 32</p>\n",
    "<p>D steps per G step = 1</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "paperback-cocktail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (25000, 32, 32, 3)\n",
      "score 4.952681 0.07228739\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan/acgan-cifar10-12/training_checkpoints/generator-e250.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "senior-buffer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "FID 75.63258687902103\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan/acgan-cifar10-12/training_checkpoints/generator-e250.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fatty-compromise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 0s 3ms/step - loss: -2.1283 - out_fake_loss: -3.1221 - out_aux_loss: 0.9937 - out_fake_accuracy: 0.0967 - out_aux_out_aux_sparse_categorical_accuracy: 0.7566\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan/acgan-cifar10-12/training_checkpoints/discriminator-e250.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-lodge",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_13 (Base model -> Bigger Batch Size)\n",
    "<p>Batch Size : 128</p>\n",
    "<p>D steps per G step = 1</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan/acgan-cifar10-13/training_checkpoints/generator-e250.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan/acgan-cifar10-13/training_checkpoints/generator-e250.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan/acgan-cifar10-13/training_checkpoints/discriminator-e250.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-figure",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_14 (Base model -> 50% fmap increase in G)\n",
    "<p>Batch Size : 64</p>\n",
    "<p>D steps per G step = 1</p>\n",
    "<p>G: all num_filters increased by 50%</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "outside-vision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (25000, 32, 32, 3)\n",
      "score 5.1913466 0.09469021\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan/acgan-cifar10-14/training_checkpoints/generator-e250.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "effective-publication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "FID 70.95198882955454\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan/acgan-cifar10-14/training_checkpoints/generator-e250.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "falling-bradford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 2.5002 - out_fake_loss: 1.8081 - out_aux_loss: 0.6921 - out_fake_accuracy: 0.1022 - out_aux_out_aux_sparse_categorical_accuracy: 0.7714\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan/acgan-cifar10-14/training_checkpoints/discriminator-e250.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-trauma",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_21 (Base model)\n",
    "<p>Batch Size : 64</p>\n",
    "<p>D steps per G step = 1</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alike-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (25000, 32, 32, 3)\n",
      "score 4.9461637 0.060329482\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan/acgan-cifar10-21/training_checkpoints/generator-e250.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "measured-correction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "FID 76.44904966044828\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan/acgan-cifar10-21/training_checkpoints/generator-e250.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "processed-saturday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 1.3525 - out_fake_loss: 0.2048 - out_aux_loss: 0.8177 - out_fake_accuracy: 0.1252 - out_aux_out_aux_sparse_categorical_accuracy: 0.7292\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan/acgan-cifar10-21/training_checkpoints/discriminator-e250.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-offering",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_24 (Base model -> 50% fmap increase in G)\n",
    "\n",
    "Batch Size : 64\n",
    "\n",
    "D steps per G step = 1\n",
    "\n",
    "G: all num_filters increased by 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "elect-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (25000, 32, 32, 3)\n",
      "score 3.2980762 0.04472773\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan/acgan-cifar10-24/training_checkpoints/generator-e250.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "electrical-farming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "FID 124.19291303984167\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan/acgan-cifar10-24/training_checkpoints/generator-e250.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "physical-victim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 0s 3ms/step - loss: -33.7820 - out_fake_loss: -34.8988 - out_aux_loss: 0.8095 - out_fake_accuracy: 0.0999 - out_aux_out_aux_sparse_categorical_accuracy: 0.7222\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan/acgan-cifar10-24/training_checkpoints/discriminator-e250.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-immune",
   "metadata": {},
   "source": [
    "# AC-BigGAN_CIFAR10_1\n",
    "<p>Batch Size : 64 </p>\n",
    "<p>D steps per G step = 1</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "waiting-sharing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (50000, 32, 32, 3)\n",
      "score 7.3396783 0.1047656\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-1/training_checkpoints/generator-e200.h5'\n",
    "calc_is_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "peripheral-radius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "diff\n",
      "FID 28.504098975812443\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-1/training_checkpoints/generator-e200.h5'\n",
    "calc_fid_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "primary-trout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 2s 10ms/step - loss: -4.3777 - out_fake_loss: -5.2616 - out_aux_loss: 0.8838 - out_fake_accuracy: 0.1352 - out_aux_out_aux_sparse_categorical_accuracy: 0.7628\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "discriminator = './history/bigacgan/bigacgan-cifar10-1/training_checkpoints/discriminator-e200.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator, custom_objects=custom_objects)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-training",
   "metadata": {},
   "source": [
    "# AC-BigGAN_CIFAR10_2\n",
    "<p>Batch Size : 128 </p>\n",
    "<p>D steps per G step = 1</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "previous-intranet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (50000, 32, 32, 3)\n",
      "score 7.553888 0.07084607\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-2/training_checkpoints/generator-e200.h5'\n",
    "calc_is_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "median-friendly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "diff\n",
      "FID 26.303061407311624\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-2/training_checkpoints/generator-e200.h5'\n",
    "calc_fid_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "radio-gallery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 2s 10ms/step - loss: -2.5928 - out_fake_loss: -3.4982 - out_aux_loss: 0.9054 - out_fake_accuracy: 0.1184 - out_aux_out_aux_sparse_categorical_accuracy: 0.7643\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "discriminator = './history/bigacgan/bigacgan-cifar10-2/training_checkpoints/discriminator-e200.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator, custom_objects=custom_objects)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-brake",
   "metadata": {},
   "source": [
    "# AC-BigGAN_CIFAR10_3\n",
    "<p>Batch Size : 64 </p>\n",
    "<p>D steps per G step = 1</p>\n",
    "<p>500 Epochs</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wireless-algebra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (50000, 32, 32, 3)\n",
      "score 7.7297907 0.05965043\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-3/training_checkpoints/generator-e500.h5'\n",
    "calc_is_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "equivalent-insertion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "FID 24.296191775205514\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-3/training_checkpoints/generator-e500.h5'\n",
    "calc_fid_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "important-botswana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 2s 10ms/step - loss: -3.1858 - out_fake_loss: -3.9841 - out_aux_loss: 0.7983 - out_fake_accuracy: 0.1191 - out_aux_out_aux_sparse_categorical_accuracy: 0.7911\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "discriminator = './history/bigacgan/bigacgan-cifar10-3/training_checkpoints/discriminator-e500.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator, custom_objects=custom_objects)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-fiction",
   "metadata": {},
   "source": [
    "# AC-BigGAN_CIFAR10_4\n",
    "<p>Batch Size : 64 </p>\n",
    "<p>D steps per G step = 1</p>\n",
    "<p>50% in feature maps</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "physical-canadian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (50000, 32, 32, 3)\n",
      "score 8.0505295 0.09688499\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-4/training_checkpoints/generator-e200.h5'\n",
    "calc_is_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "juvenile-mandate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "diff\n",
      "FID 25.222851144034152\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-4/training_checkpoints/generator-e200.h5'\n",
    "calc_fid_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "identical-customs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 3s 17ms/step - loss: -2.6317 - out_fake_loss: -3.4639 - out_aux_loss: 0.8322 - out_fake_accuracy: 0.1258 - out_aux_out_aux_sparse_categorical_accuracy: 0.8077\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "discriminator = './history/bigacgan/bigacgan-cifar10-4/training_checkpoints/discriminator-e200.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator, custom_objects=custom_objects)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-science",
   "metadata": {},
   "source": [
    "# AC-BigGAN_CIFAR10_5\n",
    "<p>Batch Size : 64 </p>\n",
    "<p>D steps per G step = 1</p>\n",
    "<p>100% in feature maps</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "polar-botswana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (50000, 32, 32, 3)\n",
      "score 7.3519144 0.10396134\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-5/training_checkpoints/generator-e200.h5'\n",
    "calc_is_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alike-gnome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "diff\n",
      "FID 25.96943480678521\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-5/training_checkpoints/generator-e200.h5'\n",
    "calc_fid_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "soviet-debut",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 3s 18ms/step - loss: -2.1741 - out_fake_loss: -3.0665 - out_aux_loss: 0.8924 - out_fake_accuracy: 0.1330 - out_aux_out_aux_sparse_categorical_accuracy: 0.7864\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "discriminator = './history/bigacgan/bigacgan-cifar10-5/training_checkpoints/discriminator-e200.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator, custom_objects=custom_objects)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-segment",
   "metadata": {},
   "source": [
    "# AC-BigGAN_CIFAR10_9\n",
    "<p>Batch Size : 64 </p>\n",
    "<p>D steps per G step = 1</p>\n",
    "\"Mistake\" fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "opponent-minnesota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (25000, 32, 32, 3)\n",
      "score 6.917647 0.14044906\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-9/training_checkpoints/generator-e200.h5'\n",
    "calc_is_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "handled-portrait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "FID 30.1998249705484\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-9/training_checkpoints/generator-e200.h5'\n",
    "calc_fid_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "equivalent-syndrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 2s 10ms/step - loss: -2.0863 - out_fake_loss: -2.7289 - out_aux_loss: 0.6427 - out_fake_accuracy: 0.1226 - out_aux_out_aux_sparse_categorical_accuracy: 0.8112\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "discriminator = './history/bigacgan/bigacgan-cifar10-9/training_checkpoints/discriminator-e200.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator, custom_objects=custom_objects)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-radar",
   "metadata": {},
   "source": [
    "# AC-BigGAN_CIFAR10_10\n",
    "Equal to 1 (has \"mistake\"), but with learning rates as in 9. Generating metrics are better, but discrimination is not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "third-belgium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (25000, 32, 32, 3)\n",
      "score 7.402719 0.08084297\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-10/training_checkpoints/generator-e200.h5'\n",
    "calc_is_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "likely-decision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "FID 28.16983880147424\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-10/training_checkpoints/generator-e200.h5'\n",
    "calc_fid_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reasonable-sudan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 1s 9ms/step - loss: -4.4029 - out_fake_loss: -5.2231 - out_aux_loss: 0.8202 - out_fake_accuracy: 0.1185 - out_aux_out_aux_sparse_categorical_accuracy: 0.7855\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "discriminator = './history/bigacgan/bigacgan-cifar10-10/training_checkpoints/discriminator-e200.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator, custom_objects=custom_objects)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-result",
   "metadata": {},
   "source": [
    "# AC-BigGAN_CIFAR10_11\n",
    "Equal to 9, but with Adam optimizer equal to the one in BigGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stuffed-advancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (25000, 32, 32, 3)\n",
      "score 6.0107837 0.114875145\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-11/training_checkpoints/generator-e200.h5'\n",
    "calc_is_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bibliographic-strain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "FID 48.680263578330255\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-11/training_checkpoints/generator-e200.h5'\n",
    "calc_fid_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "helpful-roads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 1s 9ms/step - loss: -8.0601 - out_fake_loss: -8.8943 - out_aux_loss: 0.8341 - out_fake_accuracy: 0.1143 - out_aux_out_aux_sparse_categorical_accuracy: 0.7430\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "discriminator = './history/bigacgan/bigacgan-cifar10-11/training_checkpoints/discriminator-e200.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator, custom_objects=custom_objects)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-tobago",
   "metadata": {},
   "source": [
    "# AC-BigGAN_CIFAR10_12\n",
    "Equal to 9 with 50% fmap increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "existing-standing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (25000, 32, 32, 3)\n",
      "score 6.3935156 0.118666574\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-12/training_checkpoints/generator-e200.h5'\n",
    "calc_is_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "varied-steps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "FID 37.349289036731065\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/bigacgan/bigacgan-cifar10-12/training_checkpoints/generator-e200.h5'\n",
    "calc_fid_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "automotive-cincinnati",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 2s 14ms/step - loss: -10.8508 - out_fake_loss: -11.7910 - out_aux_loss: 0.9402 - out_fake_accuracy: 0.1196 - out_aux_out_aux_sparse_categorical_accuracy: 0.7409\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "discriminator = './history/bigacgan/bigacgan-cifar10-12/training_checkpoints/discriminator-e200.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator, custom_objects=custom_objects)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
