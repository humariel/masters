{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "outstanding-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import sqrtm\n",
    "import pickle\n",
    "from scipy.stats import truncnorm\n",
    "# modules\n",
    "from Ops.spectral_normalization import SpectralConv2D, SpectralDense\n",
    "from Ops.ops import ResnetBlock, ResnetBlockUp, ResnetBlockDown\n",
    "from Ops.attention import Attention\n",
    "from Ops.global_sum_pooling import GlobalSumPooling2D\n",
    "from Ops.conditional_batch_normalization import ConditionalBatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "atmospheric-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale an array of images to a new size\n",
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        # store\n",
    "        images_list.append(new_image)\n",
    "    return np.asarray(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "optional-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes images have any shape and pixels in [0,255]\n",
    "def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
    "    # load inception v3 model\n",
    "    model = InceptionV3()\n",
    "    # enumerate splits of images/predictions\n",
    "    scores = list()\n",
    "    n_part = math.floor(images.shape[0] / n_split)\n",
    "    for i in range(n_split):\n",
    "        # retrieve images\n",
    "        ix_start, ix_end = i * n_part, (i+1) * n_part\n",
    "        subset = images[ix_start:ix_end]\n",
    "        # convert from uint8 to float32\n",
    "        subset = subset.astype('float32')\n",
    "        # scale images to the required size\n",
    "        subset = scale_images(subset, (299,299,3))\n",
    "        # pre-process images, scale to [-1,1]\n",
    "        subset = preprocess_input(subset)\n",
    "        # predict p(y|x)\n",
    "        p_yx = model.predict(subset)\n",
    "        # calculate p(y)\n",
    "        p_y = np.expand_dims(p_yx.mean(axis=0), 0)\n",
    "        # calculate KL divergence using log probabilities\n",
    "        kl_d = p_yx * (np.log(p_yx + eps) - np.log(p_y + eps))\n",
    "        # sum over classes\n",
    "        sum_kl_d = kl_d.sum(axis=1)\n",
    "        # average over images\n",
    "        avg_kl_d = np.mean(sum_kl_d)\n",
    "        # undo the log\n",
    "        is_score = np.exp(avg_kl_d)\n",
    "        # store\n",
    "        scores.append(is_score)\n",
    "    # average across images\n",
    "    is_avg, is_std = np.mean(scores), np.std(scores)\n",
    "    return is_avg, is_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "satisfied-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate frechet inception distance\n",
    "def calculate_fid(images1, images2):\n",
    "    model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
    "    # convert integer to floating point values\n",
    "    images1 = images1.astype('float32')\n",
    "    images2 = images2.astype('float32')\n",
    "    # resize images\n",
    "    images1 = scale_images(images1, (299,299,3))\n",
    "    images2 = scale_images(images2, (299,299,3))\n",
    "    # pre-process images\n",
    "    images1 = preprocess_input(images1)\n",
    "    images2 = preprocess_input(images2)\n",
    "    # calculate activations\n",
    "    act1 = model.predict(images1)\n",
    "    act2 = model.predict(images2)\n",
    "    # calculate mean and covariance statistics\n",
    "    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    print('diff')\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alive-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(n_samples, latent_dim=100, n_classes=10, bigGAN=False):\n",
    "    if not bigGAN:\n",
    "        # generate points in the latent space\n",
    "        z_input = np.random.randn(n_samples * latent_dim)\n",
    "        # reshape into a batch of inputs for the network\n",
    "        z_input = z_input.reshape(n_samples, latent_dim)\n",
    "    else:\n",
    "        z_input = truncnorm.rvs(-2, 2, size=(n_samples, latent_dim), random_state=None).astype(np.float32)\n",
    "        z_input = z_input * 2.0 # 2.0 is truncation value\n",
    "    # generate labels\n",
    "    labels = np.random.randint(0, n_classes, n_samples)\n",
    "    return [z_input, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reported-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_is_for_gan(generator, n_split=10, eps=1E-16, custom_objects=None):\n",
    "    generator = tf.keras.models.load_model(generator, custom_objects=custom_objects)\n",
    "    #generate latent points for 50k images\n",
    "    [z_input, labels] = generate_latent_points(50000)\n",
    "    images = generator.predict([z_input, labels])\n",
    "    images = (images*127.5) + 127.5\n",
    "    print('generated ', images.shape)\n",
    "    #calculate IS score\n",
    "    is_avg, is_std = calculate_inception_score(images)\n",
    "    print('score', is_avg, is_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recreational-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fid_for_gan(generator, custom_objects=None):\n",
    "    generator = tf.keras.models.load_model(generator, custom_objects=custom_objects)\n",
    "    #generate latent points for 50k images\n",
    "    [z_input, labels] = generate_latent_points(10000)\n",
    "    fake_images = generator.predict([z_input, labels])\n",
    "    fake_images = (fake_images*127.5) + 127.5\n",
    "    print('generated ', fake_images.shape)\n",
    "    (real_images, _), (_, _) = cifar10.load_data()\n",
    "    np.random.shuffle(real_images)\n",
    "    real_images = real_images[:10000]\n",
    "    #calculate FID score\n",
    "    fid = calculate_fid(real_images, fake_images)\n",
    "    print('FID', fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-separation",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-adaptation",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_1 (base model)\n",
    "<p>Batch Size : 64</p>\n",
    "<p>D steps per G step = 1</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "retained-directory",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (50000, 32, 32, 3)\n",
      "score 1.0014681 1.2479225e-05\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan-cifar10-1/training_checkpoints/generator-e100.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "preceding-anatomy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "rescaled\n",
      "preprocessed\n",
      "predicted\n",
      "mean+cov\n",
      "sum\n",
      "sqrt dot\n",
      "diff\n",
      "FID 100.01867563902042\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan-cifar10-1/training_checkpoints/generator-e100.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aggressive-association",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 1.0064 - out_fake_loss: 0.1988 - out_aux_loss: 0.8076 - out_fake_accuracy: 0.0715 - out_aux_out_aux_sparse_categorical_accuracy: 0.7548\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan-cifar10-1/training_checkpoints/discriminator-e100.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-tucson",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_2 \n",
    "<p>Batch Size : 64</p>\n",
    "<p>D steps per G step = 1</p>\n",
    "<p>D: 1 extra layer at end (compared to model 1)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "smaller-democracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (50000, 32, 32, 3)\n",
      "score 5.0143404 0.054708604\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan-cifar10-2/training_checkpoints/generator-e100.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "roman-procedure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "diff\n",
      "FID 74.89925510662314\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan-cifar10-2/training_checkpoints/generator-e100.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "legitimate-carpet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 0s 3ms/step - loss: -3.9448 - out_fake_loss: -4.8267 - out_aux_loss: 0.8819 - out_fake_accuracy: 0.0980 - out_aux_out_aux_sparse_categorical_accuracy: 0.7570\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan-cifar10-2/training_checkpoints/discriminator-e100.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-pulse",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_3\n",
    "<p>Batch Size : 64</p>\n",
    "<p>D steps per G step = 2</p>\n",
    "<p>D: 1 extra layer at start and 1 extra at start (compared to model 1)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gothic-academy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (50000, 32, 32, 3)\n",
      "score 4.8608894 0.042887427\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan-cifar10-3/training_checkpoints/generator-e100.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "optical-there",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "diff\n",
      "FID 82.24604198077853\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan-cifar10-3/training_checkpoints/generator-e100.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exact-acting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 0s 3ms/step - loss: -2.2250 - out_fake_loss: -3.0148 - out_aux_loss: 0.7898 - out_fake_accuracy: 0.0982 - out_aux_out_aux_sparse_categorical_accuracy: 0.7389\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan-cifar10-3/training_checkpoints/discriminator-e100.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-vocabulary",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_4\n",
    "<p>Batch Size : 32</p>\n",
    "<p>D steps per G step = 1</p>\n",
    "<p>D: 1 extra layer at end (compared to model 1)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "governmental-profession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (50000, 32, 32, 3)\n",
      "score 4.8894005 0.0583598\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan-cifar10-4/training_checkpoints/generator-e100.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "instrumental-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "diff\n",
      "FID 80.04588693732032\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan-cifar10-4/training_checkpoints/generator-e100.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "extended-flush",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 1s 3ms/step - loss: -3.6566 - out_fake_loss: -4.5395 - out_aux_loss: 0.8829 - out_fake_accuracy: 0.0976 - out_aux_out_aux_sparse_categorical_accuracy: 0.7511\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan-cifar10-4/training_checkpoints/discriminator-e100.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-connection",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_5\n",
    "<p>Batch Size : 128</p>\n",
    "<p>D steps per G step = 1</p>\n",
    "<p>D: 1 extra layer at end (compared to model 1)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "religious-broadcast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (50000, 32, 32, 3)\n",
      "score 4.86891 0.06767401\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan-cifar10-5/training_checkpoints/generator-e100.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "variable-drive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "diff\n",
      "FID 78.96338538974939\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan-cifar10-5/training_checkpoints/generator-e100.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "steady-cement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 1s 3ms/step - loss: -2.4877 - out_fake_loss: -3.3608 - out_aux_loss: 0.8731 - out_fake_accuracy: 0.0975 - out_aux_out_aux_sparse_categorical_accuracy: 0.7507\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan-cifar10-5/training_checkpoints/discriminator-e100.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-basic",
   "metadata": {},
   "source": [
    "## AC-GAN_CIFAR10_6\n",
    "<p>Batch Size : 64</p>\n",
    "<p>D steps per G step = 1</p>\n",
    "<p>D: 1 extra layer at end (compared to model 1)</p>\n",
    "<p>D/G: all num_filters increased by 50% (compared to model 2)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "intended-federal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (50000, 32, 32, 3)\n",
      "score 5.0004277 0.06381372\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "generator = './history/acgan-cifar10-6/training_checkpoints/generator-e100.h5'\n",
    "calc_is_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "exciting-center",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "diff\n",
      "FID 76.35711987678168\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "generator = './history/acgan-cifar10-6/training_checkpoints/generator-e100.h5'\n",
    "calc_fid_for_gan(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "possible-oxide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 1s 5ms/step - loss: -5.1907 - out_fake_loss: -6.1856 - out_aux_loss: 0.9949 - out_fake_accuracy: 0.0952 - out_aux_out_aux_sparse_categorical_accuracy: 0.7620\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "discriminator = './history/acgan-cifar10-6/training_checkpoints/discriminator-e100.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-immune",
   "metadata": {},
   "source": [
    "# AC-BigGAN_CIFAR10\n",
    "<p>Batch Size : 64 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "frank-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_is_for_bigGAN(generator, n_split=10, eps=1E-16, custom_objects=None):\n",
    "    generator = tf.keras.models.load_model(generator, custom_objects=custom_objects)\n",
    "    #generate latent points for 50k images\n",
    "    [z_input, labels] = generate_latent_points(50000, latent_dim=128, bigGAN=True)\n",
    "    images = generator.predict([z_input, labels])\n",
    "    images = (images*127.5) + 127.5\n",
    "    print('generated ', images.shape)\n",
    "    #calculate IS score\n",
    "    is_avg, is_std = calculate_inception_score(images)\n",
    "    print('score', is_avg, is_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "amber-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fid_for_bigGAN(generator, custom_objects=None):\n",
    "    generator = tf.keras.models.load_model(generator, custom_objects=custom_objects)\n",
    "    #generate latent points for 50k images\n",
    "    [z_input, labels] = generate_latent_points(10000, latent_dim=128, bigGAN=True)\n",
    "    fake_images = generator.predict([z_input, labels])\n",
    "    fake_images = (fake_images*127.5) + 127.5\n",
    "    print('generated ', fake_images.shape)\n",
    "    (real_images, _), (_, _) = cifar10.load_data()\n",
    "    np.random.shuffle(real_images)\n",
    "    real_images = real_images[:10000]\n",
    "    #calculate FID score\n",
    "    fid = calculate_fid(real_images, fake_images)\n",
    "    print('FID', fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "waiting-sharing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (50000, 32, 32, 3)\n",
      "score 7.3396783 0.1047656\n"
     ]
    }
   ],
   "source": [
    "#measure IS\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/acgan-cifar10-9/training_checkpoints/generator-e200.h5'\n",
    "calc_is_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "peripheral-radius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "generated  (10000, 32, 32, 3)\n",
      "diff\n",
      "FID 28.504098975812443\n"
     ]
    }
   ],
   "source": [
    "#measure FID\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/acgan-cifar10-9/training_checkpoints/generator-e200.h5'\n",
    "calc_fid_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "primary-trout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "157/157 [==============================] - 2s 10ms/step - loss: -4.3777 - out_fake_loss: -5.2616 - out_aux_loss: 0.8838 - out_fake_accuracy: 0.1352 - out_aux_out_aux_sparse_categorical_accuracy: 0.7628\n"
     ]
    }
   ],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "discriminator = './history/acgan-cifar10-9/training_checkpoints/discriminator-e200.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator, custom_objects=custom_objects)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-standing",
   "metadata": {},
   "source": [
    "# AC-BigGAN_CIFAR10\n",
    "<p>Batch Size : 128 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure IS\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/acgan-cifar10-10/training_checkpoints/generator-e200.h5'\n",
    "calc_is_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure FID\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "generator = './history/acgan-cifar10-10/training_checkpoints/generator-e200.h5'\n",
    "calc_fid_for_bigGAN(generator, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure accuracy on CIFAR10 test data\n",
    "custom_objects={'SpectralDense': SpectralDense, 'SpectralConv2D': SpectralConv2D}\n",
    "discriminator = './history/acgan-cifar10-9/training_checkpoints/discriminator-e200.h5'\n",
    "discriminator = tf.keras.models.load_model(discriminator, custom_objects=custom_objects)\n",
    "(_, _), (testX, testY) = cifar10.load_data()\n",
    "testX = testX.astype('float32')\n",
    "testX = (testX - 127.5) / 127.5\n",
    "_eval = discriminator.evaluate(testX, testY, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
